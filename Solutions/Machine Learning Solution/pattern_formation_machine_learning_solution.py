# -*- coding: utf-8 -*-
"""pattern_formation_machine_learning_solution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17f6d2vznlSxlfv9WXinTYciN0hTTpRJL

# Pattern Formation (Three PDE Model)

## Install Required Packages
"""

pip install py-pde numpy matplotlib

"""## Import Libraries"""

from typing import Tuple, Dict, List, Union, Type

from pde import PDEBase, ScalarField, FieldCollection, CartesianGrid, ScipySolver, MemoryStorage
from pde.grids.base import GridBase
from pde.solvers.base import SolverBase

from scipy.integrate import solve_ivp
import numpy as np
import matplotlib.pyplot as plt

"""## Definitions

### Define the Pattern Formation PDE Class (Three PDE Model)
"""

class PatternFormationPDE(PDEBase):
    """Pattern Formation Three PDE Model Class"""

    def __init__(self, params: Dict[str, float], bc: List[Dict[str, float]]) -> None:
        """Initialize the PDE model with parameters.

        Args:
            params (Dict[str, float]): Dictionary of parameters.
            fd_order (int): The order of the FD approximations.
        """

        # Call the base class constructor
        super().__init__()

        # Extract Parameters
        self.D1: float = params["D1"]
        self.D2: float = params["D2"]
        self.D3: float = params["D3"]
        self.k1: float = params["k1"]
        self.k2: float = params["k2"]
        self.k3: float = params["k3"]
        self.k4: float = params["k4"]
        self.k5: float = params["k5"]
        self.k6: float = params["k6"]
        self.k7: float = params["k7"]
        self.k8: float = params["k8"]
        self.k9: float = params["k9"]

        self.bc: List[Dict[str, float]] = bc

    def evolution_rate(self, state: FieldCollection, t: float=0) -> FieldCollection:
        """Compute the evolution rate of the system.

        Args:
            state (FieldCollection): Current state of the system.
            t (float, optional): Current time. Defaults to 0.

        Returns:
            FieldCollection: Evolution rate of the system.
        """

        u1, u2, u3 = state  # Unpack fields

        # Compute gradients with BCs
        grad_u2 = u2.gradient(bc=self.bc)

        # Diffusion terms with BCs
        diff_u1 = self.D1 * u1.laplace(bc=self.bc)
        diff_u2 = self.D2 * u2.laplace(bc=self.bc)
        diff_u3 = self.D3 * u3.laplace(bc=self.bc)

        # Chemotaxis term: -∇·[k1 u1 / (k2 + u2)² ∇u₂]
        chemotaxis_coeff = self.k1 * u1 / (self.k2 + u2) ** 2
        chemotaxis = -chemotaxis_coeff * grad_u2
        chemotaxis_div = chemotaxis.divergence(bc=self.bc)

        # Source terms
        source_u1 = self.k3 * u1 * (
                self.k4 * u3 ** 2 / (self.k9 + u3 ** 2) - u1
        )
        source_u2 = self.k5 * u3 * (
                u1 ** 2 / (self.k6 + u1 ** 2) - self.k7 * u1 * u2
        )
        source_u3 = -self.k8 * u1 * (
                u3 ** 2 / (self.k9 + u3 ** 2)
        )

        # Combine all terms
        du1_dt = diff_u1 + chemotaxis_div + source_u1
        du2_dt = diff_u2 + source_u2
        du3_dt = diff_u3 + source_u3

        return FieldCollection([du1_dt, du2_dt, du3_dt])

"""### Define Functions used for solving a PDE system"""

def set_up_initial_state(grid: GridBase, x_vals: np.ndarray, lambda_val: int=5) -> FieldCollection:
    """Set up the grid and initial state.

    Args:
        grid (GridBase): Grid of x.
        x_vals (np.ndarray): Array of x values.
        lambda_val (int, optional): Initial conditions parameter. Defaults to 5.

    Returns:
        FieldCollection: Initial state values for u1, u2, u3.
    """

    # Gaussian initial profiles centered at x=0
    u1_init = 1e8 * np.exp(-lambda_val * x_vals ** 2)  # cells/ml
    u2_init = 5e-6 * np.exp(-lambda_val * x_vals ** 2)  # M
    u3_init = 1e-3 * np.exp(-lambda_val * x_vals ** 2)  # M

    # Create fields with Neumann BCs specified
    field_u1 = ScalarField(grid, data=u1_init)
    field_u2 = ScalarField(grid, data=u2_init)
    field_u3 = ScalarField(grid, data=u3_init)
    initial_state = FieldCollection([field_u1, field_u2, field_u3])

    return initial_state

def solve_system(pde: PDEBase, solver: Union[SolverBase, str], storage: MemoryStorage, initial_state: FieldCollection, t_range: float, dt: float) -> None:
    """Solve the PDE system and store the results in storage.

    Args:
        pde (PDEBase): PDE model.
        solver (Union[SolverBase, str]): Solver to use.
        storage (MemoryStorage): Storage to use.
        initial_state (FieldCollection): Initial state.
        t_range (float): Range of time to solve for.
        dt (float): Time step.
    """

    trackers = [
        "progress",  # Progress bar
        storage.tracker(interrupts=dt)  # Store every 30 minutes
    ]
    pde.solve(
        state=initial_state,
        t_range=t_range,
        dt=dt,
        solver=solver,
        tracker=trackers
    )

"""### Define functions used to calculate accuracy"""

def get_last_state_results(analysis_points: List[float], x_vals: np.ndarray, u_vals: List[List[float]]) -> Dict[str, Dict[str, np.float64]]:
    """Get the simulation results at certian state

    Args:
        analysis_points (List[float]): The array of x values.
        x_vals (np.ndarray): The array of x values.
        u_vals (List[List[float]]): The list of u1, u2, and u3 values.

    Returns:
        Dict[str, Dict[str, np.float64]]: The simulation results at certian state
    """

    sim_results = {}
    point_indices = [int((x / x_vals[-1]) * (len(x_vals) - 1)) for x in analysis_points]

    for index in range(len(point_indices)):
        x_val = analysis_points[index]
        x_index = point_indices[index]
        u_vals_dict = {}

        u_vals_dict["u1"]: np.float64 = np.array(u_vals[0]).flatten()[x_index]
        u_vals_dict["u2"]: np.float64 = np.array(u_vals[1]).flatten()[x_index]
        u_vals_dict["u3"]: np.float64 = np.array(u_vals[2]).flatten()[x_index]

        sim_results[str(x_val)] = u_vals_dict

    return sim_results

def calc_relative_errors(true_values: Dict[str, Dict[str, float]], approximations: Dict[str, Dict[str, np.float64]]) -> Dict[str, Dict[str, float]]:
    """Calculate the relative error between true values and approximations.

    Args:
        true_values (Dict[str, Dict[str, float]]): The true expected values.
        approximations (Dict[str, Dict[str, np.float64]]): The calculated approximations.

    Returns:
        Dict[str, Dict[str, float]]: The relative errors between true values and approximations as percentages.
    """

    relative_errors: Dict[str, Dict[str, float]] = {}

    for x_val, u_vals in approximations.items():
        relative_errors[x_val] = {}

        for field, value in u_vals.items():
            relative_errors[x_val][field] = (abs(true_values[x_val][field] - value) / true_values[x_val][field]) * 100

    return relative_errors

"""### Define Functions used for showing the results"""

def print_last_state(u_vals: List[List[float]], x_vals: np.ndarray) -> None:
    """Prints the values of x, u1, u2, and u3 for the final state.

    Args:
        u_vals (List[List[float]]): The list of u1, u2, and u3 values.
        x_vals (np.ndarray): The array of x values.
    """

    print(f"\nVerifying with storage data for the final state:")
    print("x (cm)\t\tu1 (cells/ml)\t\tu2 (M)\t\t\tu3 (M)")
    print("-" * 80)

    # Print values from storage
    for j in range(len(x_vals)):
        u1_val: np.float64 = np.array(u_vals[0]).flatten()[j]
        u2_val: np.float64 = np.array(u_vals[1]).flatten()[j]
        u3_val: np.float64 = np.array(u_vals[2]).flatten()[j]

        print(f"{x_vals[j]:.4f}\t\t{u1_val:.4e}\t\t{u2_val:.4e}\t\t{u3_val:.4e}")

def plot_results(storage: MemoryStorage, x_vals: np.ndarray, no_rows: int, no_cols: int, fig_size: Tuple[int, int]) -> None:
    """Plot the results from the storage object in subplots as one figure.

    Args:
        storage (MemoryStorage): The storage object containing the state data.
        x_vals (np.ndarray): The array of x values.
        no_rows (int): Number of rows in the subplot grid.
        no_cols (int): Number of columns in the subplot grid.
        fig_size (Tuple[int, int]): Size of the figure.
    """

    fig, axes = plt.subplots(no_rows, no_cols, figsize=fig_size)

    # Get time points in seconds from storage
    time_points: np.ndarray = np.array(storage.times)

    for i, (name, ax) in enumerate(zip(["u1", "u2", "u3"], axes)):
        for t_index in range(0, len(time_points)):
            # Flatten the data arrays to 1D
            data: np.ndarray = np.array(storage.data[t_index][i].data).flatten()

            # Ensure x_vals and data have same length
            if len(x_vals) != len(data):
                x_vals: np.ndarray = np.linspace(0, 1, len(data))  # Auto-adjust x_vals to match data

            ax.plot(x_vals, data, alpha=1.0,
                    label=f"t={time_points[t_index] / 3600:.1f} hrs")

        ax.set_title(f"Evolution of {name}")
        ax.set_xlabel("Position x (cm)")
        ax.set_ylabel(name + "(x,t), t=0,0.5,...,5")
        ax.legend()
        ax.grid(True)

    plt.tight_layout()
    plt.show()

def print_relative_errors(true_values: Tuple[str, Dict[str, Dict[str, float]]], approximations: Tuple[str, Dict[str, Dict[str, np.float64]]], relative_errors: Dict[str, Dict[str, float]]) -> None:
    """Prints the relative errors between the book results and the simulation results.

    Args:
        true_values (Tuple[Dict[str, Dict[str, float]]]): Tuple has the column name and the true expected values.
        approximations (Tuple[Dict[str, Dict[str, np.float64]]]): Tuple has the column name and the calculated approximations.
        relative_errors (Dict[str, Dict[str, float]]): The relative errors between true values and approximations as percentages.
    """

    print(f"X (cm)\t\tField\t\t{approximations[0]}\t\t{true_values[0]}\t\tRelative Error")
    print("-" * 105)

    min_error: float = float("inf")
    max_error: float = float("-inf")
    min_error_field: str = ""
    max_error_field: str = ""
    min_error_x: str = ""
    max_error_x: str = ""

    for x_val, u_vals in relative_errors.items():
        print(f"x = {x_val}")

        for field, error in u_vals.items():
            if error < min_error:
                min_error = error
                min_error_field = field
                min_error_x = x_val
            if error > max_error:
                max_error = error
                max_error_field = field
                max_error_x = x_val

            print(f"\t\t{field}\t\t{approximations[1][x_val][field]:.4e}\t\t\t{true_values[1][x_val][field]:.4e}\t\t{error:.2f}%")

    print("-" * 105)
    print("\nError Analysing:")
    print(f"Maximum error: {max_error_field} at x = {max_error_x} with a value of {max_error:.2f}%")
    print(f"Minimum error: {min_error_field} at x = {min_error_x} with a value of {min_error:.2f}%")

"""### Parameter Definitions"""

# Define parameters
params: Dict[str, float] = {
    "D1": 1.999996e-06,     # cm²/s
    "D2": 8.9e-06,          # cm²/s
    "D3": 9.0e-06,          # cm²/s
    "k1": 3.9e-09,          # M·cm²/s
    "k2": 5.0e-06,          # M
    "k3": 1.62e-09,         # h⁻¹·ml/cell (converted from hr⁻¹)
    "k4": 3.5e+08,          # cells/ml
    "k5": 5.0e-07,          # (M·s)⁻¹
    "k6": 1.0e+18,          # (cells/ml)²
    "k7": 1.0e-13,          # ml/(cell·s)
    "k8": 1.0e-14,          # s⁻¹
    "k9": 4.0e-06,          # M²
}

# Define Neumann BCs (zero gradient)
neumann_bc: List[Dict[str, float]] = [{"derivative": 0}, {"derivative": 0}]

# Set up the solver (ScipySolver)
solver: Type[ScipySolver] = ScipySolver  # More robust solver for stiff systems

# Define x boundries
bounds: Tuple[float, float] = (0, 1)

# Define reqiured paremeters for comparing results
analysis_points: np.ndarray = np.array([0.0, 0.2, 0.4, 0.6, 0.8, 1.0]) # x values = 0, 0.2, 0.4, 0.6, 0.8, 1 cm

# Book results at t = 5 hours
book_results: Dict[str, Dict[str, float]] = {
                                              "0.0": {"u1": 1.034e7, "u2": 2.480e-6, "u3": 3.449e-4},
                                              "0.2": {"u1": 9.783e6, "u2": 2.384e-6, "u3": 3.358e-4},
                                              "0.4": {"u1": 8.333e6, "u2": 2.133e-6, "u3": 3.116e-4},
                                              "0.6": {"u1": 6.603e6, "u2": 1.824e-6, "u3": 2.803e-4},
                                              "0.8": {"u1": 5.294e6, "u2": 1.576e-6, "u3": 2.541e-4},
                                              "1.0": {"u1": 4.825e6, "u2": 1.481e-6, "u3": 2.438e-4}
                                            }

"""## The System using grid in x with 51 support points

### PDE System Initialization and Simulation Setup
"""

# Initiate the PDE system
pde_system: PatternFormationPDE = PatternFormationPDE(params, bc=neumann_bc)

# Create storage to store data and times
storage: MemoryStorage = MemoryStorage()

# Set up grid with 51 points ranged from 0 to 1
number_of_points: int = 51
grid: GridBase = CartesianGrid([bounds], [number_of_points])
x_vals: np.ndarray = np.linspace(bounds[0], bounds[1], number_of_points)

# Set up initial state
initial_state: FieldCollection = set_up_initial_state(grid, x_vals)

"""### Solve and Print Final State Data"""

# Solve the PDE system
solve_system(pde_system, solver, storage, initial_state, t_range=18000, dt=1800)

# Extract data
last_state_index = len(storage.times) - 1 # last index at t = 5 h
u_vals = [
    storage.data[last_state_index][0].data,
    storage.data[last_state_index][1].data,
    storage.data[last_state_index][2].data
]

# Print the last state at t = 5 hours
print_last_state(u_vals, x_vals)

"""### Plot Results"""

plot_results(storage, x_vals, no_rows=1, no_cols=3, fig_size=(18, 6))

"""### Comparing between learning-based results and chapter results

#### Accuracy
"""

# Get the simulation results at t = 5 hours and x = 0, 0.2, 0.4, 0.6, 0.8, 1 cm
sim_results = get_last_state_results(analysis_points, x_vals, u_vals)

# Calculate relative error at t = 5 h and x = 0, 0.2, 0.4, 0.6, 0.8, 1 cm
relative_errors: Dict[str, Dict[str, float]] = calc_relative_errors(book_results, sim_results)

# Print relative errors between book results and simulation results
print_relative_errors(("Book Results", book_results), ("Simulation Results", sim_results), relative_errors)

"""#### Time Metrics

| Metric             | learning-based Simulation          | Book Implementation |
| ------------------ | ------------------------------- | ---------------------------- |
| *Runtime*        | 6.922 s (real)                  | Not reported                 |
| *Function Evals* | 10 solver steps                 | 831 ncall                  |
| *Problem Size*   | 153 ODEs (3 fields × 51 points) | 153 ODEs                     |

## Suggestions for improvements and future work

### h Refinement

**Solving the System using grid with higher support points in x (For example nx=101)**

#### PDE System Initialization and Simulation Setup
"""

# Initiate the PDE system
pde_system_h_refine: PatternFormationPDE = PatternFormationPDE(params, bc=neumann_bc)

# Create storage to store data and times
storage_h_refine: MemoryStorage = MemoryStorage()

# Set up grid with 101 points ranged from 0 to 1
number_of_points_h_refine: int = 101
grid_h_refine: GridBase = CartesianGrid([bounds], [number_of_points_h_refine])
x_vals_h_refine: np.ndarray = np.linspace(bounds[0], bounds[1], number_of_points_h_refine)

# Set up initial state
initial_state_h_refine: FieldCollection = set_up_initial_state(grid_h_refine, x_vals_h_refine)

"""#### Solve and Print Final State Data"""

# Solve the PDE system
solve_system(pde_system_h_refine, solver, storage_h_refine, initial_state_h_refine, t_range=18000, dt=1800)

# Extract data
last_state_index_h_refine = len(storage_h_refine.times) - 1 # last index at t = 5 h
u_vals_h_refine = [
    storage_h_refine.data[last_state_index_h_refine][0].data,
    storage_h_refine.data[last_state_index_h_refine][1].data,
    storage_h_refine.data[last_state_index_h_refine][2].data
]

# Print the last state at t = 5 hours
print_last_state(u_vals_h_refine, x_vals_h_refine)

"""#### Plot Results"""

plot_results(storage_h_refine, x_vals_h_refine, no_rows=1, no_cols=3, fig_size=(18, 6))

"""#### Comparing between results before and after the h refinement"""

# Get simulation results at the last state (t = 5 hours)
sim_results_h_refine = get_last_state_results(analysis_points, x_vals_h_refine, u_vals_h_refine)

# Calculate relative error at t = 5 h and x = 0, 0.2, 0.4, 0.6, 0.8, 1 cm
relative_errors: Dict[str, Dict[str, float]] = calc_relative_errors(sim_results, sim_results_h_refine)

# Print relative errors between simulation results before and after h refinement
print_relative_errors(("Simulation before h refinement", sim_results), ("Simulation after h refinement", sim_results_h_refine), relative_errors)

"""### p Refinement

**Solve the System using higher-order FD approximations (For example use sixth-order FD approximations)**

#### Definitions

Unfortunately, as of now, `py-pde` does not offer built-in 6th-order accurate derivative stencils directly via its public API.

**But we can define our own functions.**

##### Define functions to calculate sixth-order FD approximations
"""

def get_first_derivative_6th_order(xl, xu, n, u):
    h = (xu - xl) / (n - 1)
    ux = np.zeros(n)
    # Left boundary
    ux[0] = (-147*u[0] + 360*u[1] - 450*u[2] + 400*u[3] - 225*u[4] + 72*u[5] - 10*u[6]) / (60*h)
    # Near-left points
    ux[1] = (-10*u[0] - 77*u[1] + 150*u[2] - 100*u[3] + 50*u[4] - 15*u[5] + 2*u[6]) / (60*h)
    ux[2] = (2*u[0] - 24*u[1] - 35*u[2] + 80*u[3] - 30*u[4] + 8*u[5] - u[6]) / (60*h)
    # Interior points
    for i in range(3, n-3):
        ux[i] = (-u[i-3] + 9*u[i-2] - 45*u[i-1] + 45*u[i+1] - 9*u[i+2] + u[i+3]) / (60*h)
    # Near-right points
    ux[n-3] = (u[n-7] - 8*u[n-6] + 30*u[n-5] - 80*u[n-4] + 35*u[n-3] + 24*u[n-2] - 2*u[n-1]) / (60*h)
    ux[n-2] = (-2*u[n-7] + 15*u[n-6] - 50*u[n-5] + 100*u[n-4] - 150*u[n-3] + 77*u[n-2] + 10*u[n-1]) / (60*h)
    # Right boundary
    ux[n-1] = (10*u[n-7] - 72*u[n-6] + 225*u[n-5] - 400*u[n-4] + 450*u[n-3] - 360*u[n-2] + 147*u[n-1]) / (60*h)
    return ux

def get_second_derivative_6th_order(xl, xu, n, u, ux, n1, nu):
    # Compute second derivative via double application of first derivative
    uxx = get_first_derivative_6th_order(xl, xu, n, ux)
    return uxx

"""##### Define the PDE system"""

def three_pde_model(t, y, xl, xu, nx, params):
    # Unpack parameters
    D1: float = params["D1"]
    D2: float = params["D2"]
    D3: float = params["D3"]
    k1: float = params["k1"]
    k2: float = params["k2"]
    k3: float = params["k3"]
    k4: float = params["k4"]
    k5: float = params["k5"]
    k6: float = params["k6"]
    k7: float = params["k7"]
    k8: float = params["k8"]
    k9: float = params["k9"]

    # Split solution vector into u1, u2, u3
    u1 = np.maximum(y[0:nx], 0)  # Enforce non-negativity
    u2 = np.maximum(y[nx:2*nx], 0)
    u3 = np.maximum(y[2*nx:3*nx], 0)

    # Compute first derivatives
    u1x = get_first_derivative_6th_order(xl, xu, nx, u1)
    u2x = get_first_derivative_6th_order(xl, xu, nx, u2)
    u3x = get_first_derivative_6th_order(xl, xu, nx, u3)

    # Apply Neumann BCs (zero flux)
    u1x[0] = 0; u1x[-1] = 0
    u2x[0] = 0; u2x[-1] = 0
    u3x[0] = 0; u3x[-1] = 0

    # Compute second derivatives
    u1xx = get_second_derivative_6th_order(xl, xu, nx, u1, u1x, 2, 2)
    u2xx = get_second_derivative_6th_order(xl, xu, nx, u2, u2x, 2, 2)
    u3xx = get_second_derivative_6th_order(xl, xu, nx, u3, u3x, 2, 2)

    # Precompute common terms
    den = 1 / (k2 + u2)**2
    chem_term = k1 * u1 * den * u2xx
    chem_term += k1 * den * u1x * u2x
    chem_term -= 2 * k1 * u1 * den / (k2 + u2) * u2x**2

    # Evaluate PDEs
    u1t = D1 * u1xx - chem_term + k3 * u1 * (k4 * u3**2 / (k9 + u3**2) - u1)
    u2t = D2 * u2xx + k5 * u3 * (u1**2 / (k6 + u1**2)) - k7 * u1 * u2
    u3t = D3 * u3xx - k8 * u1 * (u3**2 / (k9 + u3**2))

    return np.concatenate([u1t, u2t, u3t])

"""##### Parameters Definetions"""

# Spatial grid
number_of_points_p_refine: int = 51

# Time points (5 hours in seconds)
t_span = (0, 5 * 3600)
t_eval = np.linspace(0, 5 * 3600, 11)

"""#### Setup initial conditions"""

# Get x values of the grid
x_vals_p_refine = np.linspace(bounds[0], bounds[1], number_of_points_p_refine)

# Initial conditions (Gaussian)
u10 = 1.0e+08 * np.exp(-5 * x_vals_p_refine**2)
u20 = 5.0e-06 * np.exp(-5 * x_vals_p_refine**2)
u30 = 1.0e-03 * np.exp(-5 * x_vals_p_refine**2)
y0 = np.concatenate([u10, u20, u30])

"""#### Solve and Print Final State Data"""

# Solve with 6th-order method
sol6 = solve_ivp(
    three_pde_model, t_span, y0, t_eval=t_eval,
    args=(bounds[0], bounds[1], number_of_points_p_refine, params),
    method='BDF', rtol=1e-6, atol=1e-8
)

# Extract final solutions
u_vals_p_refine = [
    sol6.y[:number_of_points_p_refine, -1],
    sol6.y[number_of_points_p_refine:2*number_of_points_p_refine, -1],
    sol6.y[2*number_of_points_p_refine:, -1]
]

# Print the last state at t = 5 hours
print_last_state(u_vals_p_refine, x_vals_p_refine)

"""#### Plot the results"""

fig, axes = plt.subplots(1, 3, figsize=(18, 6))

for i, (name, ax) in enumerate(zip(["u1", "u2", "u3"], axes)):
    for t_index in range(0, len(t_eval)):
        data: np.ndarray = np.zeros(number_of_points_p_refine)

        if i == 0:
            data = sol6.y[0:number_of_points_p_refine, t_index]
        elif i == 1:
            data = sol6.y[number_of_points_p_refine:2*number_of_points_p_refine, t_index]
        else:
            data = sol6.y[2*number_of_points_p_refine:, t_index]

        # Ensure x_vals and data have same length
        if len(x_vals_p_refine) != len(data):
            x_vals_p_refine: np.ndarray = np.linspace(0, 1, len(data))  # Auto-adjust x_vals to match data

        ax.plot(x_vals_p_refine, data, alpha=1.0,
                label=f"t={t_eval[t_index] / 3600:.1f} hrs")

    ax.set_title(f"Evolution of {name}")
    ax.set_xlabel("Position x (cm)")
    ax.set_ylabel(name + "(x,t), t=0,0.5,...,5")
    ax.legend()
    ax.grid(True)

plt.tight_layout()
plt.show()

"""#### Comparing between results before and after the p refinement"""

# Get Simulation results at the last state (t = 5 hours)
sim_results_p_refine = get_last_state_results(analysis_points, x_vals_p_refine, u_vals_p_refine)

# Calculate relative error at t = 5 h and x = 0, 0.2, 0.4, 0.6, 0.8, 1 cm
relative_errors: Dict[str, Dict[str, float]] = calc_relative_errors(sim_results, sim_results_p_refine)

# Print relative errors between simulation results before and after p refinement
print_relative_errors(("Simulation before p refinement", sim_results), ("Simulation after p refinement", sim_results_p_refine), relative_errors)